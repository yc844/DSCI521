{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment group 2: Network and exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module D _(40 pts)_ An ingredient-based recommender system\n",
    "In this module we're going to build a recommender system using some recipes data and the Apriori algorithm. These data can be obtained from Kaggle:\n",
    "\n",
    "- https://www.kaggle.com/kaggle/recipe-ingredients-dataset\n",
    "\n",
    "and are packaged with the assignment in the following directory:\n",
    "\n",
    "- `./data/train.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D1.__ _(2 pts)_ To start, load the recipe data from `json` format and print the first 5 recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}, {'id': 25693, 'cuisine': 'southern_us', 'ingredients': ['plain flour', 'ground pepper', 'salt', 'tomatoes', 'ground black pepper', 'thyme', 'eggs', 'green tomatoes', 'yellow corn meal', 'milk', 'vegetable oil']}, {'id': 20130, 'cuisine': 'filipino', 'ingredients': ['eggs', 'pepper', 'salt', 'mayonaise', 'cooking oil', 'green chilies', 'grilled chicken breasts', 'garlic powder', 'yellow onion', 'soy sauce', 'butter', 'chicken livers']}, {'id': 22213, 'cuisine': 'indian', 'ingredients': ['water', 'vegetable oil', 'wheat', 'salt']}, {'id': 13162, 'cuisine': 'indian', 'ingredients': ['black pepper', 'shallots', 'cornflour', 'cayenne pepper', 'onions', 'garlic paste', 'milk', 'butter', 'salt', 'lemon juice', 'water', 'chili powder', 'passata', 'oil', 'ground cumin', 'boneless chicken skinless thigh', 'garam masala', 'double cream', 'natural yogurt', 'bay leaf']}]\n"
     ]
    }
   ],
   "source": [
    "## code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "json_data = open('./data/train.json')\n",
    "data = json.load(json_data)\n",
    "#print first 5 recipes\n",
    "recipes = data[0:5]\n",
    "print(recipes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D2.__ _(5 pts)_ Next, `from collections import Counter` to write a function called `count_items(recipes)` that counts up the number of recipes that include each `ingredient`, storing each in the counter as a single-element tuple (for downstream convienience), i.e., incrementing like `counts[tuple([ingredient])] +=1`. \n",
    "\n",
    "When complete, exhibit this functions utility in application to the `recipes` loaded in __D1__ and print the number of 'candidates' in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('romaine lettuce',): 1,\n",
       "         ('black olives',): 1,\n",
       "         ('grape tomatoes',): 1,\n",
       "         ('garlic',): 1,\n",
       "         ('pepper',): 2,\n",
       "         ('purple onion',): 1,\n",
       "         ('seasoning',): 1,\n",
       "         ('garbanzo beans',): 1,\n",
       "         ('feta cheese crumbles',): 1,\n",
       "         ('plain flour',): 1,\n",
       "         ('ground pepper',): 1,\n",
       "         ('salt',): 4,\n",
       "         ('tomatoes',): 1,\n",
       "         ('ground black pepper',): 1,\n",
       "         ('thyme',): 1,\n",
       "         ('eggs',): 2,\n",
       "         ('green tomatoes',): 1,\n",
       "         ('yellow corn meal',): 1,\n",
       "         ('milk',): 2,\n",
       "         ('vegetable oil',): 2,\n",
       "         ('mayonaise',): 1,\n",
       "         ('cooking oil',): 1,\n",
       "         ('green chilies',): 1,\n",
       "         ('grilled chicken breasts',): 1,\n",
       "         ('garlic powder',): 1,\n",
       "         ('yellow onion',): 1,\n",
       "         ('soy sauce',): 1,\n",
       "         ('butter',): 2,\n",
       "         ('chicken livers',): 1,\n",
       "         ('water',): 2,\n",
       "         ('wheat',): 1,\n",
       "         ('black pepper',): 1,\n",
       "         ('shallots',): 1,\n",
       "         ('cornflour',): 1,\n",
       "         ('cayenne pepper',): 1,\n",
       "         ('onions',): 1,\n",
       "         ('garlic paste',): 1,\n",
       "         ('lemon juice',): 1,\n",
       "         ('chili powder',): 1,\n",
       "         ('passata',): 1,\n",
       "         ('oil',): 1,\n",
       "         ('ground cumin',): 1,\n",
       "         ('boneless chicken skinless thigh',): 1,\n",
       "         ('garam masala',): 1,\n",
       "         ('double cream',): 1,\n",
       "         ('natural yogurt',): 1,\n",
       "         ('bay leaf',): 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here\n",
    "from collections import Counter\n",
    "def count_items(recipes):\n",
    "    counts = Counter()\n",
    "    for recipe in recipes:\n",
    "        ingredients = recipe['ingredients']\n",
    "        for ingredient in ingredients:\n",
    "            counts[tuple([ingredient])] += 1\n",
    "    return counts\n",
    "\n",
    "# test\n",
    "count_items(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D3.__ _(5 pts)_ Now, write a function called `store_frequent(candidates, threshold = 25)`, which accepts a `Counter` of `candidates`, i.e., item or itemset counts, and stores only those with count above the determined `threshold` value in a separate counter called `frequent`, which is `return`ed at the end of the function. Apply this function to your output from __D1__ with the default `threshold` value of `25` to exhibit your function's utility, and then print the number of frequent items found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'black pepper': 39749, 'shallots': 39749, 'cornflour': 39749, 'cayenne pepper': 39749, 'onions': 39749, 'garlic paste': 39749, 'milk': 39749, 'butter': 39749, 'salt': 39749, 'lemon juice': 39749, 'water': 39749, 'chili powder': 39749, 'passata': 39749, 'oil': 39749, 'ground cumin': 39749, 'boneless chicken skinless thigh': 39749, 'garam masala': 39749, 'double cream': 39749, 'natural yogurt': 39749, 'bay leaf': 39749})\n"
     ]
    }
   ],
   "source": [
    "## code here\n",
    "def store_frequent(candidates, threshold=25):\n",
    "    counts = Counter()\n",
    "    frequent = Counter()\n",
    "    for candidate in candidates:\n",
    "        counts[candidate] += 1\n",
    "        if counts[candidate] > threshold:\n",
    "            frequent[candidate] += 1\n",
    "    return frequent\n",
    "\n",
    "#counting frequency\n",
    "ingredient_list = []\n",
    "for ingredient in data:\n",
    "    ingredient = recipe['ingredients']\n",
    "    ingredient_list.append(ingredient)\n",
    "Ing=ingredient_list[:]\n",
    "flattened = [val for sublist in Ing for val in sublist]\n",
    "count=store_frequent(flattened)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D4.__ (10 pts) Now, write a function called `get_next(recipes, frequent, threshold = 25)` that accepts the `frequent` items output from the `store_frequent()` function. With these inputs, your function should:\n",
    "\n",
    "1. create a new `Counter` called `next_candidates`\n",
    "2. compute the `size` of the itemsets for `next_candidates` from a single key in `frequent`\n",
    "3. `for` any `recipe` with _at least_ as many ingredients as `size`:\n",
    "    1. loop over all itemsets of size `size` (see combinations note below)\n",
    "    2. utilize the apriori principle and subsets of itemsets to count up potentially-frequent candidate itemsets in `next_candidates`\n",
    "4. `return(next_candidates)` \n",
    "\n",
    "__Important__: once your code runs, apply this function to the output of __D3__, report the resulting number of `next_candidates` found, and run `store_frequent` on these to report the number of 2-itemsets that were frequent. Repeat this process to build the 3-itemsets and record in the markdown box any observations on run time for these successive applications. In the response box below reply to the following questions:\n",
    "\n",
    "- Are we generating more candidates or frequent itemsets as we look at larger sizes? \n",
    "- Why would this process become more and more computationally expensive as the size get's larger?\n",
    "    \n",
    "Note: to complete this part it is _extremely strongly_ encouraged that you import the `combinations()` function from the `itertools` module. With this, you can execute `combinations(items, k)` to find all combinations of size `k` from a list of `items`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "def get_next(recipes, frequent, threshold=25):\n",
    "    next_candidates = Counter()\n",
    "    for k, v in frequent:\n",
    "        set_size = frequent.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D5.__ (10 pts) Now that we have the pieces to run Apriori/collect frequent itemsets it's time to package the process together, collecting all frequent itemsets up to a particular `size`. To do this, write a function called `train(recipes, size = 4)`, which:\n",
    "\n",
    "1. initializes two empty dictionaries, `candidates`, and `frequent`;\n",
    "2. runs the `count_items` and `store_frequent` function, storing output in the `candidates`, and `frequent` dictionaries using the integer `1` as a key;\n",
    "3. loops over sizes: 2, 3, .., `size` to compute and store the subsequent sizes candidates and frequent itemsets in the same structure as (2), but now utilizing the `get_next` function, instead of `count_items`; and\n",
    "4. `return`s the `candidates` and `frequent` itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D5.__ _(8 pts)_ Now that we have our `frequent` itemsets up to `size`, we can utilize them to recommend missing ingredients from ingredient 'baskets' of at most `size - 1`. To do this, write a function called `recommend(basket, frequent)` that does the following: \n",
    "\n",
    "1. initializes an empty `recommendations` list\n",
    "2. loops over all frequent `itemset`s of `size 1 greater than the `basket`\n",
    "    - if there's one item left from the `itemset` when the `basket` removed, append the remaining item to the `recommendations` list in a tuple, with the number of ocurrences of the itemset in the second position\n",
    "4. `return` `recommendations`, but sorted from high to low by itemset ocurrence.\n",
    "\n",
    "Once your code is complete, report the top 10 recommended items to buy for recipe flexibility in the following scenarios:\n",
    "\n",
    "- `basket = tuple(['butter', 'flour'])`\n",
    "- `basket = tuple(['soy sauce', 'green onions'])`\n",
    "- `basket = tuple(['avocado', 'garlic', 'salt'])`\n",
    "\n",
    "and in the response box below discuss the output and the types of recipes you think the recommender is pointing you to. Does this output seem appropriate? \n",
    "\n",
    "Note: your function should additionally respond appropriately if the user requests a recommendation for a basket of size at least as big as the `size` specified in the `train()` function, i.e., it should return an error message gracefully, alerting the user to not having trained on itemsets large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
